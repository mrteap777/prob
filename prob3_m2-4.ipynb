{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания аналитического дашборда, который позволяет анализировать загруженность станций в течение дня, нам нужно вычислить и визуализировать различные метрики. Мы добавим возможность выбора временных интервалов и станций, а также рассчитаем ключевые метрики, такие как загруженность станций, пропускная способность и другие.\n",
    "\n",
    "Вот обновленный код для Streamlit-дэшборда:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Настройка подключения к базе данных PostgreSQL\n",
    "DB_HOST = 'your_db_host'\n",
    "DB_NAME = 'your_db_name'\n",
    "DB_USER = 'your_db_user'\n",
    "DB_PASS = 'your_db_password'\n",
    "\n",
    "# Создание подключения к базе данных\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def get_db_connection():\n",
    "    engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}/{DB_NAME}')\n",
    "    return engine\n",
    "\n",
    "# Загрузка данных из базы данных\n",
    "@st.cache\n",
    "def load_data():\n",
    "    engine = get_db_connection()\n",
    "    query = \"SELECT * FROM your_table_name\"  # Измените на ваше название таблицы\n",
    "    df = pd.read_sql(query, engine)\n",
    "    return df\n",
    "\n",
    "# Фильтрация данных по выбранным станциям и временным интервалам\n",
    "def filter_data(df, stations, start_time, end_time):\n",
    "    filtered_df = df[\n",
    "        (df['станция входа'].isin(stations) | df['станция выхода'].isin(stations)) &\n",
    "        (df['время входа'] >= start_time) &\n",
    "        (df['время выхода'] <= end_time)\n",
    "    ]\n",
    "    return filtered_df\n",
    "\n",
    "# Кластеризация данных\n",
    "def perform_clustering(df):\n",
    "    df = df.copy()\n",
    "    # Преобразование времени в количество секунд с начала дня для удобства кластеризации\n",
    "    df['время входа (сек)'] = df['время входа'].dt.hour * 3600 + df['время входа'].dt.minute * 60 + df['время входа'].dt.second\n",
    "    df['время выхода (сек)'] = df['время выхода'].dt.hour * 3600 + df['время выхода'].dt.minute * 60 + df['время выхода'].dt.second\n",
    "\n",
    "    # Выбор признаков для кластеризации\n",
    "    features = df[['время входа (сек)', 'время выхода (сек)', 'длительность поездки']].dropna()\n",
    "\n",
    "    # Применение KMeans для кластеризации на 3 кластера\n",
    "    kmeans = KMeans(n_clusters=3, random_state=0).fit(features)\n",
    "    df['кластер'] = kmeans.labels_\n",
    "\n",
    "    return df\n",
    "\n",
    "# Основная функция для создания дашборда\n",
    "def main():\n",
    "    st.title(\"Аналитический дашборд\")\n",
    "\n",
    "    # Загрузка данных\n",
    "    df = load_data()\n",
    "    df['время входа'] = pd.to_datetime(df['время входа'])\n",
    "    df['время выхода'] = pd.to_datetime(df['время выхода'])\n",
    "    df['длительность поездки'] = df['время выхода'] - df['время входа']\n",
    "\n",
    "    # Интерфейс для выбора станций и временного интервала\n",
    "    stations = st.multiselect('Выберите станции', df['станция входа'].unique())\n",
    "    start_time = st.slider('Начальное время', min_value=datetime(2023, 6, 1, 0, 0), max_value=datetime(2023, 6, 1, 23, 59), value=datetime(2023, 6, 1, 8, 0))\n",
    "    end_time = st.slider('Конечное время', min_value=datetime(2023, 6, 1, 0, 0), max_value=datetime(2023, 6, 1, 23, 59), value=datetime(2023, 6, 1, 20, 0))\n",
    "\n",
    "    # Фильтрация данных\n",
    "    filtered_df = filter_data(df, stations, start_time, end_time)\n",
    "\n",
    "    # Вычисление метрик для выбранного интервала\n",
    "    station_load = filtered_df['станция входа'].value_counts() + filtered_df['станция выхода'].value_counts()\n",
    "    max_load = station_load.max()\n",
    "    station_load_percent = (station_load / max_load) * 100 if max_load != 0 else 0\n",
    "    average_capacity = station_load.mean()\n",
    "    top_stations = station_load.nlargest(5)\n",
    "    entry_count = filtered_df['станция входа'].value_counts()\n",
    "    exit_count = filtered_df['станция выхода'].value_counts()\n",
    "    average_trip_duration = filtered_df['длительность поездки'].mean()\n",
    "\n",
    "    # Кластеризация данных\n",
    "    clustered_df = perform_clustering(filtered_df)\n",
    "\n",
    "    # Визуализация данных\n",
    "    st.header(\"Основные метрики\")\n",
    "    st.metric(\"Средняя пропускная способность\", f\"{average_capacity:.2f}\")\n",
    "    st.metric(\"Средняя продолжительность поездки\", f\"{average_trip_duration}\")\n",
    "\n",
    "    st.header(\"Загруженность станций (%)\")\n",
    "    st.bar_chart(station_load_percent)\n",
    "\n",
    "    st.header(\"Топ загруженных станций\")\n",
    "    st.bar_chart(top_stations)\n",
    "\n",
    "    st.header(\"Количество входов на станции\")\n",
    "    st.bar_chart(entry_count)\n",
    "\n",
    "    st.header(\"Количество выходов на станции\")\n",
    "    st.bar_chart(exit_count)\n",
    "\n",
    "    st.header(\"Кластеры поездок\")\n",
    "    st.write(\"0: Оптимальные поездки, 1: Нежелательные поездки, 2: Следует воздержаться\")\n",
    "    st.dataframe(clustered_df[['станция входа', 'станция выхода', 'время входа', 'время выхода', 'длительность поездки', 'кластер']])\n",
    "\n",
    "    # Анализ загруженности станций в течение дня\n",
    "    st.header(\"Анализ загруженности станций в течение дня\")\n",
    "    hourly_load = filtered_df.set_index('время входа').groupby(pd.Grouper(freq='H')).size()\n",
    "    st.line_chart(hourly_load)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объяснение кода:\n",
    "Подключение к базе данных: Используем SQLAlchemy для подключения к PostgreSQL.\n",
    "Загрузка данных: Загружаем данные из базы данных и кэшируем их для повышения производительности.\n",
    "Фильтрация данных: Фильтруем данные по выбранным станциям и временным интервалам.\n",
    "Вычисление метрик: Вычисляем основные метрики, такие как загруженность станций, пропускная способность и средняя продолжительность поездки.\n",
    "Кластеризация данных: Применяем алгоритм KMeans для кластеризации данных на 3 кластера. Включаем результаты кластеризации в таблицу данных.\n",
    "Визуализация данных: Создаем графики и метрики, отображающие ключевые показатели и результаты кластеризации.\n",
    "Анализ загруженности станций в течение дня: Добавляем анализ загруженности станций в течение дня и визуализируем его с помощью линейного графика."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Этот обновленный дашборд позволяет пользователю проводить анализ загруженности станций в течение дня, задавать временные интервалы и выбирать станции, а также визуализировать результаты кластеризации поездок на 3 кластера, что поможет в принятии решений о поездках.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
